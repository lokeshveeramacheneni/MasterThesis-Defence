\documentclass[aspectratio=169]{beamer}


\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{ragged2e}  % `\justifying` text
\usepackage{booktabs}  % Tables
\usepackage{tabularx}
\usepackage{tikz}      % Diagrams
\usetikzlibrary{calc, shapes, backgrounds}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{dsfont}
\usepackage{url}       % `\url
\usepackage{listings}  % Code listings
\usepackage[T1]{fontenc}


\usepackage{theme/beamerthemehbrs}

\author[Veeramacheneni]{Lokesh Veeramacheneni}
\title{Out-of-Distribution Detection in 3D Semantic Segmentation}
\subtitle{Master Thesis}
\institute[HBRS]{Hochschule Bonn-Rhein-Sieg}
\date{September 02, 2022}
\subject{Test beamer}

% leave the value of this argument empty if the advisors
% should not be included on the title slide
\def\advisors{Prof. Dr. Paul G Pl\"{o}ger, Prof. Dr. Matias Valdenegro Toro, Prof. Dr. Sebastian Houben}

\thirdpartylogo{images/DFKI.png}


\begin{document}
{
\begin{frame}
\titlepage
\end{frame}
}

\section{Introduction}
% 1. Discuss about what is OOD
% and need for OOD along with some real life examples
% 2. Explain about 3D Semantic segmentation task
\begin{frame}{Out-of-Distribution detection}
    \begin{itemize}
        \item An ideal trustworthy visual recognition system
        \begin{itemize}
            \item Produce accurate predictions on known examples
            \item Detect and reject unknown examples
        \end{itemize}
        \item Deep Neural Networks (DNNs) are trained based on closed world assumption
        \item closed world assumption - test data is assumed to be drawn from same distribution as training data which is called In-Distribution (ID)
        \item When deployed in real world (open world scenario) the test samples can be Out-of-Distribution (OOD) i.e. the test samples can be,
        \begin{itemize}
            \item from different class
            \item from different domain 
        \end{itemize}
    \end{itemize}
\end{frame}
\begin{frame}{Out-of-Distribution detection}
 \begin{columns}
    \begin{column}{0.5\textwidth}
        \begin{itemize}
            \item A real world example for OOD object is described in Figure~\ref{fig:eg_tesla_moon}
            \item Tesla autonomous driving system detects the moon as the yellow traffic light
            \item These faulty predictions might result in output of the autonomous driving system being catastrophic
        \end{itemize}
    \end{column}
    \begin{column}{0.5\textwidth}
     \begin{figure}
         \centering
         \includegraphics[scale=0.25]{images/Tesla_ex_moon.png}
         \caption{Caption}
         \label{fig:eg_tesla_moon}
     \end{figure}
    \end{column}
 \end{columns}
\end{frame}
\begin{frame}{Importance of OOD detection}
    \begin{columns}
       \begin{column}{0.5\textwidth}
        \begin{itemize}
            \item Figure~\ref{fig:eg_apollo_pipeline} depicts the pipeline of modules in Apollo driving platform.
            \item Prediction and motion planning module are dependent on perception module.
            \item A misdetection of an OOD sample will propogate the error to motion planning and affects the total vehicle control and this might lead to unfortunate consequence
        \end{itemize}
       \end{column}
       \begin{column}{0.5\textwidth}
            \begin{figure}
                \centering
                \includegraphics[scale=0.35]{images/apollo_pipeline.png}
                \caption{Caption}
                \label{fig:eg_apollo_pipeline}
            \end{figure}
       \end{column}
    \end{columns}
\end{frame}
\begin{frame}{3D Light Detection And Ranging (LiDAR)}
    \begin{columns}
       \begin{column}{0.5\textwidth}
            \begin{itemize}
                \item Uses pulsed lasers to find the range to the objects
                \item Unlike images, LiDAR is insusceptible to illumination and provide rich 3D information.
                \item Figure~\ref{fig:sample_lidar_pc} depicts the sample point cloud with LiDAR is placed in round white circle found at the center of point cloud
                \item Typically, features of each point in point cloud include 
                \begin{itemize}
                    \item spatial features (XYZ)
                    \item Color (RGB)
                    \item Intensity
                \end{itemize}
            \end{itemize}
       \end{column}
       \begin{column}{0.5\textwidth}
            \begin{figure}
                \centering
                \includegraphics[scale=0.25]{images/sample_LiDAR_PC.png}
                \caption{Caption}
                \label{fig:sample_lidar_pc}
            \end{figure}
       \end{column}
    \end{columns}
\end{frame}
\begin{frame}{3D Semantic Segmentation}
    \begin{columns}
       \begin{column}{0.4\textwidth}
            \begin{itemize}
                \item An important task in computer vision because of its use in scene understanding
                \item Further helps in navigation and planning of robots
                \item Objective - Assign each point in the point cloud a specific class
            \end{itemize}       
       \end{column}
       \begin{column}{0.6\textwidth}
            \begin{figure}
                \centering
                %\includegraphics[scale=0.15]{images/sample_LiDAR_PC.png}
                %\includegraphics[scale=0.15]{images/sample_LiDAR_PC_segmented.png}
                \includegraphics[scale=0.3]{images/sample_LiDAR_PC_segmented.png}
                \caption{Caption}
                \label{fig:sample_lidar_pc_segmented}
            \end{figure}
       \end{column}
    \end{columns}
\end{frame}

\begin{frame}{Thesis objective}

\begin{itemize}
    \item OOD detection in the 3D semantic segmentation setting
    \item Create a benchmark datasets for OOD detection among existing 3D LiDAR datasets. We define OOD data based on two categories
    \begin{itemize}
        \item if the point is from different class than training data
        \item if the point has inferior quality
    \end{itemize}
    \item We also study whether uncertainty estimation is a practical approach for OOD detection in 3D domain
\end{itemize}
    
\end{frame}
\section{Methodology}
% Explain about what are the requirements for setup one by one such as
% Datasets & benchmarking, OOD method, 3D Model, Uncertainty methods, Evaluation metrics
\section{Experiments \& Results}
% Arrange the experiments and explain the results here
\section{Conclusion}
\begin{frame}{Lessons Learned}
    Learning's during the duration of the thesis are
    \begin{enumerate}
        \item Training and evaluation of 3D DNNs are time consuming and resource intensive.
        \item Finding the proper prior for Flipout layers is hard and currently we use brute force to find the best fitting prior.
        \item OOD benchmarking require in depth analysis of datasets like studying the structural similarties in the datasets and also color spectrum.
        \item LiDAR datasets have large memory requirements especially for the preprocessing and metric computation.
        \item Getting 100\% OOD detection performance is not possible with the post-hoc methods used as some points in the ID dataset also have low probability scores.
    \end{enumerate}
\end{frame}
\begin{frame}{Conclusion}
    
\end{frame}
\begin{frame}{Future Work}
    This thesis can be extended in the following ways.
    \begin{enumerate}
        \item This thesis is limited to only point based models, this can be extended to graph and projection based models.
        \item The datasets involved are only static datasets and this thesis study can be further extended to other type of datasets such as synthetic and sequential datasets.
        \item Since this thesis utilzes post-hoc threshold methods for OOD detection. Other methods such as Mahalanobis distance based OOD detection \cite{lee2018simple_mahalanobis} or MetaSeg \cite{MetaSeg} can be added as an extension to this thesis.
    \end{enumerate}
\end{frame}
\begin{frame}{References}
    \bibliographystyle{plain}
    \bibliography{bibliography.bib}

\end{frame}

%\section{First section}
%\subsection{A subsection}

%\begin{frame}{Jabberwocky}
%      \framesubtitle{Lewis Carroll}%
%      \begin{tikzpicture}[overlay,remember picture]
%        \node[anchor=south east,xshift=-30pt,yshift=35pt]
%          at (current page.south east) {
%            %\includegraphics[width=35mm]{resources/jabberwocky-light}
%          };
%      \end{tikzpicture}%
%      'Twas brillig, and the slithy toves\\
%      Did gyre and gimble in the wabe;\\
%      All mimsy were the borogoves,\\
%      And the mome raths outgrabe.\\\bigskip

%      “Beware the Jabberwock, my son!\\
%      The jaws that bite, the claws that catch!\\
%      Beware the Jubjub bird, and shun\\
%      The frumious Bandersnatch!”\\
%\end{frame}

%--- Next Frame ---%
\begin{frame}{What is OOD Detection?}
    \begin{figure}
        \centering
        \includegraphics[scale=0.3]{images/OOD_ex_new.png}
        \caption{Generalized Out-of-Distribution Detection: A Survey}
        \label{fig:my_label}
    \end{figure}
\end{frame}


\end{document}
